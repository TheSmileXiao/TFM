{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73025,"status":"ok","timestamp":1718743649070,"user":{"displayName":"Xiao Yang","userId":"09168788974519610105"},"user_tz":-120},"id":"RbBTFWa790xh","outputId":"c77ec57a-907e-4d45-a871-898004a6dcbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.35-py3-none-any.whl (782 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/782.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.2/782.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m778.2/782.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m782.8/782.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.35 ultralytics-thop-2.0.0\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"dDakO0lK97aI","executionInfo":{"status":"ok","timestamp":1718743653080,"user_tz":-120,"elapsed":4017,"user":{"displayName":"Xiao Yang","userId":"09168788974519610105"}}},"outputs":[],"source":["import zipfile\n","import os\n","import shutil\n","from ultralytics          import YOLO\n","from google.colab         import drive\n","import random\n","import tqdm"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28637,"status":"ok","timestamp":1718743681706,"user":{"displayName":"Xiao Yang","userId":"09168788974519610105"},"user_tz":-120},"id":"pY5ZYHBx99MW","outputId":"efca0ee5-a50c-49c1-9c6a-7a0b2ed84bfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"8IYmdCgiWTpw"},"source":["## YOLO_DATASET SHUFFLED + COCO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8o2nBYZ9-9m"},"outputs":[],"source":["ruta_archivo_zip = '/content/drive/MyDrive/TFM_Xiao/Anotaciones/yolo_dataset.zip'\n","ruta_destino = './'\n","with zipfile.ZipFile(ruta_archivo_zip, 'r') as archivo_zip:\n","    # Extraer el archivo deseado en la ruta de destino\n","    archivo_zip.extractall(ruta_destino)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOAXZ7eORvkW"},"outputs":[],"source":["ruta_archivo_zip = '/content/drive/MyDrive/TFM_Xiao/Anotaciones/coco-seg_5000samples.zip'\n","ruta_destino = './'\n","with zipfile.ZipFile(ruta_archivo_zip, 'r') as archivo_zip:\n","    # Extraer el archivo deseado en la ruta de destino\n","    archivo_zip.extractall(ruta_destino)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2527,"status":"ok","timestamp":1715561168221,"user":{"displayName":"XIAO YANG","userId":"10498861279155438245"},"user_tz":-120},"id":"AWnAa5voScJV","outputId":"05dc88a6-d3e1-47d1-a10e-3895e37a121e"},"outputs":[{"name":"stdout","output_type":"stream","text":["3500 images have been move.\n","1000 images have been move.\n","500 images have been move.\n"]}],"source":["img_dir = '/content/coco-images'\n","labels_dir = '/content/coco_annotation'\n","dst_dir = '/content/yolo_dataset'\n","def add_coco_dataset(img_dir, labels_dir, dst_dir, train_size=0.7, val_size=0.2, test_size=0.1):\n","  random.seed(42)\n","  imgs = os.listdir(img_dir)\n","  random.shuffle(imgs)\n","  length = len(imgs)\n","\n","  train_end = int(train_size * length)\n","  val_end = train_end + int(val_size * length)\n","\n","  train_imgs = imgs[:train_end]\n","  val_imgs = imgs[train_end:val_end]\n","  test_imgs = imgs[val_end:]\n","\n","  for img in [img for img in train_imgs if img.endswith('.jpg')]:\n","    shutil.copy(os.path.join(img_dir, img), os.path.join(dst_dir, 'images/train'))\n","    shutil.copy(os.path.join(labels_dir, f\"{img.split('.')[0]}.txt\"), os.path.join(dst_dir, 'labels/train'))\n","  print(f'{train_end} images have been move.')\n","  for img in [img for img in val_imgs if img.endswith('.jpg')]:\n","    shutil.copy(os.path.join(img_dir, img), os.path.join(dst_dir, 'images/val'))\n","    shutil.copy(os.path.join(labels_dir, f\"{img.split('.')[0]}.txt\"), os.path.join(dst_dir, 'labels/val'))\n","  print(f'{val_end-train_end} images have been move.')\n","  for img in [img for img in test_imgs if img.endswith('.jpg')]:\n","    shutil.copy(os.path.join(img_dir, img), os.path.join(dst_dir, 'images/test'))\n","    shutil.copy(os.path.join(labels_dir, f\"{img.split('.')[0]}.txt\"), os.path.join(dst_dir, 'labels/test'))\n","  print(f'{length-val_end} images have been move.')\n","\n","add_coco_dataset(img_dir, labels_dir, dst_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11483,"status":"ok","timestamp":1715561186295,"user":{"displayName":"XIAO YANG","userId":"10498861279155438245"},"user_tz":-120},"id":"tzu0iXLE-CXq","outputId":"07ff2118-aa31-4fb6-aa57-7641500b776e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9c-seg.pt to 'yolov9c-seg.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53.9M/53.9M [00:00<00:00, 63.3MB/s]"]},{"name":"stdout","output_type":"stream","text":["WARNING âš ï¸ yolov9c-seg.pt appears to require 'dill', which is not in ultralytics requirements.\n","AutoInstall will run now for 'dill' but this feature will be removed in the future.\n","Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['dill'] not found, attempting AutoUpdate...\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Collecting dill\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 116.3/116.3 kB 4.0 MB/s eta 0:00:00\n","Installing collected packages: dill\n","Successfully installed dill-0.3.8\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 6.0s, installed 1 package: ['dill']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","YOLOv9c-seg summary: 654 layers, 27897120 parameters, 0 gradients, 159.4 GFLOPs\n"]},{"data":{"text/plain":["(654, 27897120, 0, 159.41411839999998)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# Load a model\n","model = YOLO('yolov9c-seg.yaml')  # build a new model from YAML\n","model = YOLO('yolov9c-seg.pt')  # load a pretrained model (recommended for training)\n","model.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1cvEAOTVJ7uD","outputId":"1811d2a8-c51e-45d1-ce33-2d4ae83fafce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.14 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov9c-seg.pt, data=/content/yolo_dataset/dataset.yaml, epochs=50, time=None, patience=10, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models, name=segment, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_coco/segment\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n","  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n","  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n","  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n","  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n","  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n","  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n"," 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n"," 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n"," 22        [15, 18, 21]  1   7951459  ultralytics.nn.modules.head.Segment          [81, 32, 256, [256, 512, 512]]\n","YOLOv9c-seg summary: 654 layers, 27897891 parameters, 27897875 gradients, 159.4 GFLOPs\n","\n","Transferred 999/999 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_coco/segment', view at http://localhost:6006/\n","Freezing layer 'model.0.conv.weight'\n","Freezing layer 'model.0.bn.weight'\n","Freezing layer 'model.0.bn.bias'\n","Freezing layer 'model.1.conv.weight'\n","Freezing layer 'model.1.bn.weight'\n","Freezing layer 'model.1.bn.bias'\n","Freezing layer 'model.2.cv1.conv.weight'\n","Freezing layer 'model.2.cv1.bn.weight'\n","Freezing layer 'model.2.cv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv2.1.conv.weight'\n","Freezing layer 'model.2.cv2.1.bn.weight'\n","Freezing layer 'model.2.cv2.1.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv3.1.conv.weight'\n","Freezing layer 'model.2.cv3.1.bn.weight'\n","Freezing layer 'model.2.cv3.1.bn.bias'\n","Freezing layer 'model.2.cv4.conv.weight'\n","Freezing layer 'model.2.cv4.bn.weight'\n","Freezing layer 'model.2.cv4.bn.bias'\n","Freezing layer 'model.3.cv1.conv.weight'\n","Freezing layer 'model.3.cv1.bn.weight'\n","Freezing layer 'model.3.cv1.bn.bias'\n","Freezing layer 'model.3.cv2.conv.weight'\n","Freezing layer 'model.3.cv2.bn.weight'\n","Freezing layer 'model.3.cv2.bn.bias'\n","Freezing layer 'model.4.cv1.conv.weight'\n","Freezing layer 'model.4.cv1.bn.weight'\n","Freezing layer 'model.4.cv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv2.1.conv.weight'\n","Freezing layer 'model.4.cv2.1.bn.weight'\n","Freezing layer 'model.4.cv2.1.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv3.1.conv.weight'\n","Freezing layer 'model.4.cv3.1.bn.weight'\n","Freezing layer 'model.4.cv3.1.bn.bias'\n","Freezing layer 'model.4.cv4.conv.weight'\n","Freezing layer 'model.4.cv4.bn.weight'\n","Freezing layer 'model.4.cv4.bn.bias'\n","Freezing layer 'model.5.cv1.conv.weight'\n","Freezing layer 'model.5.cv1.bn.weight'\n","Freezing layer 'model.5.cv1.bn.bias'\n","Freezing layer 'model.5.cv2.conv.weight'\n","Freezing layer 'model.5.cv2.bn.weight'\n","Freezing layer 'model.5.cv2.bn.bias'\n","Freezing layer 'model.6.cv1.conv.weight'\n","Freezing layer 'model.6.cv1.bn.weight'\n","Freezing layer 'model.6.cv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv2.1.conv.weight'\n","Freezing layer 'model.6.cv2.1.bn.weight'\n","Freezing layer 'model.6.cv2.1.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv3.1.conv.weight'\n","Freezing layer 'model.6.cv3.1.bn.weight'\n","Freezing layer 'model.6.cv3.1.bn.bias'\n","Freezing layer 'model.6.cv4.conv.weight'\n","Freezing layer 'model.6.cv4.bn.weight'\n","Freezing layer 'model.6.cv4.bn.bias'\n","Freezing layer 'model.7.cv1.conv.weight'\n","Freezing layer 'model.7.cv1.bn.weight'\n","Freezing layer 'model.7.cv1.bn.bias'\n","Freezing layer 'model.7.cv2.conv.weight'\n","Freezing layer 'model.7.cv2.bn.weight'\n","Freezing layer 'model.7.cv2.bn.bias'\n","Freezing layer 'model.8.cv1.conv.weight'\n","Freezing layer 'model.8.cv1.bn.weight'\n","Freezing layer 'model.8.cv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv2.1.conv.weight'\n","Freezing layer 'model.8.cv2.1.bn.weight'\n","Freezing layer 'model.8.cv2.1.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv3.1.conv.weight'\n","Freezing layer 'model.8.cv3.1.bn.weight'\n","Freezing layer 'model.8.cv3.1.bn.bias'\n","Freezing layer 'model.8.cv4.conv.weight'\n","Freezing layer 'model.8.cv4.bn.weight'\n","Freezing layer 'model.8.cv4.bn.bias'\n","Freezing layer 'model.9.cv1.conv.weight'\n","Freezing layer 'model.9.cv1.bn.weight'\n","Freezing layer 'model.9.cv1.bn.bias'\n","Freezing layer 'model.9.cv5.conv.weight'\n","Freezing layer 'model.9.cv5.bn.weight'\n","Freezing layer 'model.9.cv5.bn.bias'\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.75G total, 6.25G reserved, 1.12G allocated, 7.38G free\n","      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n","    27897891       159.4         6.898         60.26           nan        (1, 3, 640, 640)                    list\n","    27897891       318.8         2.059         58.59           nan        (2, 3, 640, 640)                    list\n","    27897891       637.7         3.242         71.64           nan        (4, 3, 640, 640)                    list\n","    27897891        1275         5.524         138.5           nan        (8, 3, 640, 640)                    list\n","    27897891        2551        10.110         392.3           nan       (16, 3, 640, 640)                    list\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 3 for CUDA:0 11.70G/14.75G (79%) âœ…\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/labels/train.cache... 50548 images, 38 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50548/50548 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/yolo_dataset/images/train/Otras_2_001471.jpg: 1 duplicate labels removed\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels/val.cache... 14434 images, 7 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14434/14434 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_coco/segment/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 163 weight(decay=0.0), 174 weight(decay=0.0004921875), 173 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_coco/segment\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/50      6.99G      1.142      1.717      1.015      1.018         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [56:42<00:00,  4.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:50<00:00,  8.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.527      0.396      0.391      0.259      0.507      0.384      0.373      0.222\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/50      3.22G      1.177      1.753     0.8906       1.04         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [58:21<00:00,  4.81it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [05:08<00:00,  7.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.446      0.353      0.342      0.223      0.441      0.338      0.326      0.194\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/50      3.02G      1.191      1.773     0.8969      1.058          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [57:57<00:00,  4.85it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [05:07<00:00,  7.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.463      0.331      0.308      0.203      0.468      0.322      0.296      0.177\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/50       2.8G      1.174      1.746     0.8668      1.059         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [57:20<00:00,  4.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [05:06<00:00,  7.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.483      0.345      0.337      0.223      0.485      0.336      0.327      0.196\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/50      3.04G      1.134      1.674     0.8095      1.041         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [56:51<00:00,  4.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [05:03<00:00,  7.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.459      0.382      0.353      0.229      0.448      0.367      0.338      0.202\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/50      2.87G      1.108      1.629     0.7815      1.029         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [56:27<00:00,  4.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [05:09<00:00,  7.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.599      0.384      0.399      0.265      0.573      0.376      0.378       0.23\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/50      2.98G      1.095      1.607     0.7617      1.021         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [56:23<00:00,  4.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:59<00:00,  8.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.565       0.41      0.421      0.287      0.562      0.394      0.405      0.247\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/50      2.89G      1.082       1.58     0.7463      1.014         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [56:06<00:00,  5.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:58<00:00,  8.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158       0.52      0.427      0.427      0.291      0.503      0.413      0.406       0.25\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/50      3.11G      1.072      1.562     0.7342      1.009          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [55:57<00:00,  5.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:59<00:00,  8.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.528      0.432      0.433      0.297      0.525      0.414      0.415      0.256\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/50      2.79G      1.062      1.549     0.7215      1.005          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [55:36<00:00,  5.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:57<00:00,  8.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158       0.56      0.432      0.438        0.3      0.549      0.421       0.42      0.258\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/50      2.86G      1.053      1.537      0.713      1.001         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [55:20<00:00,  5.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:58<00:00,  8.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.577      0.433      0.445      0.305      0.563      0.421      0.426      0.261\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      12/50      2.84G       1.05       1.52     0.7096     0.9987         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [55:30<00:00,  5.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:56<00:00,  8.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.586       0.44      0.456      0.312      0.578       0.42      0.434      0.268\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      13/50      2.99G      1.044      1.513     0.7006      0.994         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [55:19<00:00,  5.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:54<00:00,  8.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.567      0.445      0.461      0.317      0.572      0.428      0.442      0.272\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      14/50      2.81G      1.039      1.502     0.6948     0.9922         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [56:45<00:00,  4.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:55<00:00,  8.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.565       0.45      0.465      0.321      0.558      0.433      0.446      0.276\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      15/50         3G      1.034      1.494     0.6901     0.9928          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [54:43<00:00,  5.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:50<00:00,  8.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.578      0.446      0.468      0.325      0.568      0.435       0.45       0.28\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      16/50      2.93G      1.031      1.488      0.684     0.9888         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [54:34<00:00,  5.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:48<00:00,  8.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.571      0.453      0.469      0.327       0.57      0.437      0.452      0.281\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      17/50      3.07G      1.025       1.48     0.6787     0.9871          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [54:34<00:00,  5.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:48<00:00,  8.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.582      0.454      0.472       0.33      0.593      0.435      0.454      0.283\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      18/50      2.84G      1.021      1.475     0.6731     0.9846         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [54:18<00:00,  5.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:47<00:00,  8.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.595      0.453      0.476      0.332      0.602      0.433      0.458      0.285\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      19/50      3.17G      1.019      1.467     0.6731     0.9834          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [54:06<00:00,  5.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:47<00:00,  8.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.584      0.458      0.478      0.333      0.603      0.431       0.46      0.287\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      20/50      2.83G      1.017      1.464     0.6687     0.9822         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [54:15<00:00,  5.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:47<00:00,  8.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.586      0.461       0.48      0.335      0.586      0.444      0.462      0.287\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      21/50      3.14G      1.011      1.451      0.661     0.9789         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [54:21<00:00,  5.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:50<00:00,  8.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.589      0.463      0.481      0.335        0.6      0.438      0.463      0.288\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      22/50      2.78G      1.007      1.446     0.6613     0.9792         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16850/16850 [54:04<00:00,  5.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2406/2406 [04:46<00:00,  8.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      14434     103158      0.605      0.454      0.484      0.337      0.611      0.438      0.466      0.289\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      23/50      2.75G      1.005      1.443     0.6552     0.9759         10        640:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14172/16850 [45:41<09:40,  4.61it/s]"]}],"source":["# Train the model\n","model.train(data='/content/yolo_dataset/dataset.yaml', epochs=50, patience=10, imgsz=640, freeze=10, verbose=True, batch=-1, exist_ok=True,\n","      project='/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models', name='yolo_v9_coco/segment')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pIvJSugELtCx"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir '/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_coco/segment'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12397,"status":"ok","timestamp":1714350471049,"user":{"displayName":"XIAO YANG","userId":"10498861279155438245"},"user_tz":-120},"id":"ylzxbGHnrTe-","outputId":"32237d53-c189-44b6-e294-07b09e4733b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING âš ï¸ /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9/segment/weights/best.pt appears to require 'dill', which is not in ultralytics requirements.\n","AutoInstall will run now for 'dill' but this feature will be removed in the future.\n","Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['dill'] not found, attempting AutoUpdate...\n","Collecting dill\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 116.3/116.3 kB 4.0 MB/s eta 0:00:00\n","Installing collected packages: dill\n","Successfully installed dill-0.3.8\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 6.0s, installed 1 package: ['dill']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","YOLOv9c-seg summary: 654 layers, 27897891 parameters, 0 gradients, 159.4 GFLOPs\n"]},{"data":{"text/plain":["(654, 27897891, 0, 159.4184192)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model = YOLO('/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_coco/segment/weights/best.pt')\n","model.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmEGhQZquBcn"},"outputs":[],"source":["# Checking the test set (change from val rute to test rute in yaml file.)\n","model.val(data='/content/yolo_dataset/dataset.yaml')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1714351005686,"user":{"displayName":"XIAO YANG","userId":"10498861279155438245"},"user_tz":-120},"id":"6Po3EK2nSCOK","outputId":"56c2ee4d-4cb8-4987-faa9-34a2135e4d4a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9/segment/test/'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import shutil\n","shutil.move('/content/runs/segment/val/', '/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9/segment/test/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mU74v20iQiKI"},"outputs":[],"source":["drive.flush_and_unmount()"]},{"cell_type":"markdown","metadata":{"id":"KGO8M2M0WnYo"},"source":["## YOLO_DATASET VIDEO STREAM + COCO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77VKMri3WnYo"},"outputs":[],"source":["ruta_archivo_zip = '/content/drive/MyDrive/TFM_Xiao/Anotaciones/video_yolo_dataset.zip'\n","ruta_destino = './'\n","with zipfile.ZipFile(ruta_archivo_zip, 'r') as archivo_zip:\n","    # Extraer el archivo deseado en la ruta de destino\n","    archivo_zip.extractall(ruta_destino)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sv_N1P2pWnYo"},"outputs":[],"source":["ruta_archivo_zip = '/content/drive/MyDrive/TFM_Xiao/Anotaciones/coco-seg_5000samples.zip'\n","ruta_destino = './'\n","with zipfile.ZipFile(ruta_archivo_zip, 'r') as archivo_zip:\n","    # Extraer el archivo deseado en la ruta de destino\n","    archivo_zip.extractall(ruta_destino)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1999,"status":"ok","timestamp":1716772795736,"user":{"displayName":"XIAO YANG","userId":"10498861279155438245"},"user_tz":-120},"id":"8KmhSDK9WnYo","outputId":"929fa09d-33de-4ac7-fcbd-f629dafe6927"},"outputs":[{"name":"stdout","output_type":"stream","text":["4000 images have been move.\n","1000 images have been move.\n","0 images have been move.\n"]}],"source":["img_dir = '/content/coco-images'\n","labels_dir = '/content/coco_annotation'\n","dst_dir = '/content/yolo_dataset'\n","def add_coco_dataset(img_dir, labels_dir, dst_dir, train_size=0.8, val_size=0.2, test_size=1):\n","  imgs = os.listdir(img_dir)\n","  random.shuffle(imgs)\n","  length = len(imgs)\n","\n","  train_end = int(train_size * length)\n","  val_end = train_end + int(val_size * length)\n","\n","  train_imgs = imgs[:train_end]\n","  val_imgs = imgs[train_end:val_end]\n","  test_imgs = imgs[val_end:]\n","\n","  for img in [img for img in train_imgs if img.endswith('.jpg')]:\n","    shutil.copy(os.path.join(img_dir, img), os.path.join(dst_dir, 'images/train'))\n","    shutil.copy(os.path.join(labels_dir, f\"{img.split('.')[0]}.txt\"), os.path.join(dst_dir, 'labels/train'))\n","  print(f'{train_end} images have been move.')\n","  for img in [img for img in val_imgs if img.endswith('.jpg')]:\n","    shutil.copy(os.path.join(img_dir, img), os.path.join(dst_dir, 'images/val'))\n","    shutil.copy(os.path.join(labels_dir, f\"{img.split('.')[0]}.txt\"), os.path.join(dst_dir, 'labels/val'))\n","  print(f'{val_end-train_end} images have been move.')\n","  for img in [img for img in test_imgs if img.endswith('.jpg')]:\n","    shutil.copy(os.path.join(img_dir, img), os.path.join(dst_dir, 'images/test'))\n","    shutil.copy(os.path.join(labels_dir, f\"{img.split('.')[0]}.txt\"), os.path.join(dst_dir, 'labels/test'))\n","  print(f'{length-val_end} images have been move.')\n","\n","add_coco_dataset(img_dir, labels_dir, dst_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10683,"status":"ok","timestamp":1716685196255,"user":{"displayName":"XIAO YANG","userId":"10498861279155438245"},"user_tz":-120},"id":"U-P6WrdCWnYp","outputId":"9e8d3dbc-f9b7-447f-b066-5a4fb6f62316"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9c-seg.pt to 'yolov9c-seg.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53.9M/53.9M [00:00<00:00, 73.7MB/s]"]},{"name":"stdout","output_type":"stream","text":["WARNING âš ï¸ yolov9c-seg.pt appears to require 'dill', which is not in ultralytics requirements.\n","AutoInstall will run now for 'dill' but this feature will be removed in the future.\n","Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['dill'] not found, attempting AutoUpdate...\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Collecting dill\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 116.3/116.3 kB 3.4 MB/s eta 0:00:00\n","Installing collected packages: dill\n","Successfully installed dill-0.3.8\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 5.7s, installed 1 package: ['dill']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","YOLOv9c-seg summary: 654 layers, 27897120 parameters, 0 gradients, 159.4 GFLOPs\n"]},{"data":{"text/plain":["(654, 27897120, 0, 159.41411839999998)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Load a model\n","model = YOLO('yolov9c-seg.yaml')  # build a new model from YAML\n","model = YOLO('yolov9c-seg.pt')  # load a pretrained model (recommended for training)\n","model.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"z7ySHa3mWnYp","outputId":"0ebbf67e-07b5-4cab-958a-fe2ffd72c716"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.22 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov9c-seg.pt, data=/content/yolo_dataset/dataset.yaml, epochs=50, time=None, patience=10, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models, name=segment, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 4.32MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=80 with nc=81\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n","  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n","  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n","  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n","  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n","  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n","  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n"," 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n"," 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n"," 22        [15, 18, 21]  1   7951459  ultralytics.nn.modules.head.Segment          [81, 32, 256, [256, 512, 512]]\n","YOLOv9c-seg summary: 654 layers, 27897891 parameters, 27897875 gradients, 159.4 GFLOPs\n","\n","Transferred 993/999 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment', view at http://localhost:6006/\n","Freezing layer 'model.0.conv.weight'\n","Freezing layer 'model.0.bn.weight'\n","Freezing layer 'model.0.bn.bias'\n","Freezing layer 'model.1.conv.weight'\n","Freezing layer 'model.1.bn.weight'\n","Freezing layer 'model.1.bn.bias'\n","Freezing layer 'model.2.cv1.conv.weight'\n","Freezing layer 'model.2.cv1.bn.weight'\n","Freezing layer 'model.2.cv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv2.1.conv.weight'\n","Freezing layer 'model.2.cv2.1.bn.weight'\n","Freezing layer 'model.2.cv2.1.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv3.1.conv.weight'\n","Freezing layer 'model.2.cv3.1.bn.weight'\n","Freezing layer 'model.2.cv3.1.bn.bias'\n","Freezing layer 'model.2.cv4.conv.weight'\n","Freezing layer 'model.2.cv4.bn.weight'\n","Freezing layer 'model.2.cv4.bn.bias'\n","Freezing layer 'model.3.cv1.conv.weight'\n","Freezing layer 'model.3.cv1.bn.weight'\n","Freezing layer 'model.3.cv1.bn.bias'\n","Freezing layer 'model.3.cv2.conv.weight'\n","Freezing layer 'model.3.cv2.bn.weight'\n","Freezing layer 'model.3.cv2.bn.bias'\n","Freezing layer 'model.4.cv1.conv.weight'\n","Freezing layer 'model.4.cv1.bn.weight'\n","Freezing layer 'model.4.cv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv2.1.conv.weight'\n","Freezing layer 'model.4.cv2.1.bn.weight'\n","Freezing layer 'model.4.cv2.1.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv3.1.conv.weight'\n","Freezing layer 'model.4.cv3.1.bn.weight'\n","Freezing layer 'model.4.cv3.1.bn.bias'\n","Freezing layer 'model.4.cv4.conv.weight'\n","Freezing layer 'model.4.cv4.bn.weight'\n","Freezing layer 'model.4.cv4.bn.bias'\n","Freezing layer 'model.5.cv1.conv.weight'\n","Freezing layer 'model.5.cv1.bn.weight'\n","Freezing layer 'model.5.cv1.bn.bias'\n","Freezing layer 'model.5.cv2.conv.weight'\n","Freezing layer 'model.5.cv2.bn.weight'\n","Freezing layer 'model.5.cv2.bn.bias'\n","Freezing layer 'model.6.cv1.conv.weight'\n","Freezing layer 'model.6.cv1.bn.weight'\n","Freezing layer 'model.6.cv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv2.1.conv.weight'\n","Freezing layer 'model.6.cv2.1.bn.weight'\n","Freezing layer 'model.6.cv2.1.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv3.1.conv.weight'\n","Freezing layer 'model.6.cv3.1.bn.weight'\n","Freezing layer 'model.6.cv3.1.bn.bias'\n","Freezing layer 'model.6.cv4.conv.weight'\n","Freezing layer 'model.6.cv4.bn.weight'\n","Freezing layer 'model.6.cv4.bn.bias'\n","Freezing layer 'model.7.cv1.conv.weight'\n","Freezing layer 'model.7.cv1.bn.weight'\n","Freezing layer 'model.7.cv1.bn.bias'\n","Freezing layer 'model.7.cv2.conv.weight'\n","Freezing layer 'model.7.cv2.bn.weight'\n","Freezing layer 'model.7.cv2.bn.bias'\n","Freezing layer 'model.8.cv1.conv.weight'\n","Freezing layer 'model.8.cv1.bn.weight'\n","Freezing layer 'model.8.cv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv2.1.conv.weight'\n","Freezing layer 'model.8.cv2.1.bn.weight'\n","Freezing layer 'model.8.cv2.1.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv3.1.conv.weight'\n","Freezing layer 'model.8.cv3.1.bn.weight'\n","Freezing layer 'model.8.cv3.1.bn.bias'\n","Freezing layer 'model.8.cv4.conv.weight'\n","Freezing layer 'model.8.cv4.bn.weight'\n","Freezing layer 'model.8.cv4.bn.bias'\n","Freezing layer 'model.9.cv1.conv.weight'\n","Freezing layer 'model.9.cv1.bn.weight'\n","Freezing layer 'model.9.cv1.bn.bias'\n","Freezing layer 'model.9.cv5.conv.weight'\n","Freezing layer 'model.9.cv5.bn.weight'\n","Freezing layer 'model.9.cv5.bn.bias'\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 21.3MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.75G total, 0.33G reserved, 0.25G allocated, 14.16G free\n","      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]},{"name":"stdout","output_type":"stream","text":["    27897891       159.4         0.921         68.51           nan        (1, 3, 640, 640)                    list\n","    27897891       318.8         1.518         49.97           nan        (2, 3, 640, 640)                    list\n","    27897891       637.7         2.701         69.09           nan        (4, 3, 640, 640)                    list\n","    27897891        1275         4.987         134.8           nan        (8, 3, 640, 640)                    list\n","    27897891        2551         9.573         264.2           nan       (16, 3, 640, 640)                    list\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 14 for CUDA:0 9.02G/14.75G (61%) âœ…\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/labels/train... 59234 images, 34 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59234/59234 [01:27<00:00, 679.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_dataset/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels/val... 12473 images, 11 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12473/12473 [00:14<00:00, 839.86it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /content/yolo_dataset/images/val/Otras_2_001471.jpg: 1 duplicate labels removed\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset/labels/val.cache\n","Plotting labels to /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 163 weight(decay=0.0), 174 weight(decay=0.000546875), 173 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/50      6.86G      1.151      1.699      1.047      0.983        142        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [44:48<00:00,  1.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/446 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:44<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.509      0.351      0.358      0.238      0.497       0.34      0.341      0.202\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/50      6.05G      1.163      1.685     0.8212     0.9948        204        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:59<00:00,  1.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:47<00:00,  1.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.509      0.269      0.272      0.171      0.511      0.257      0.261      0.149\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/50      6.14G      1.179        1.7     0.8173      1.009        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:31<00:00,  1.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:48<00:00,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.506      0.254      0.245      0.152      0.513      0.232      0.234      0.129\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/50      6.14G      1.152      1.657     0.7808      1.003        172        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:20<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:44<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.525      0.317      0.321       0.21      0.517      0.305      0.305      0.179\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/50      6.03G      1.118      1.592      0.736     0.9882        216        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:18<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.547      0.343      0.354      0.236      0.542      0.334      0.342      0.204\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/50         6G      1.095      1.548     0.7094     0.9803         89        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:17<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.549      0.362      0.379      0.253      0.544      0.352      0.363      0.217\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/50      5.97G      1.079      1.525      0.692     0.9741         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:15<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:44<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.582      0.374      0.405      0.275       0.57      0.365      0.388      0.235\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/50      5.99G      1.068      1.494      0.677     0.9688         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:17<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.571      0.393      0.422      0.292      0.569      0.379      0.403      0.245\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/50      5.96G      1.058      1.479     0.6676     0.9647         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:15<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.541      0.414      0.426      0.295      0.557      0.403      0.412      0.252\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/50         6G      1.052      1.467     0.6583     0.9616        112        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:18<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.567      0.413      0.434      0.301      0.574      0.396      0.418      0.258\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/50      5.93G      1.044      1.455     0.6546     0.9595        231        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:17<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031       0.58      0.424      0.453      0.317      0.595      0.404      0.436      0.272\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      12/50      5.98G      1.037      1.447     0.6445     0.9571        145        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:17<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:42<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.585      0.442      0.458      0.323      0.572      0.427      0.439      0.276\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      13/50      6.04G      1.034      1.439     0.6407     0.9545        168        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:21<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.596       0.44       0.46      0.325      0.586       0.43      0.445      0.279\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      14/50      5.87G      1.029      1.428     0.6332     0.9507        113        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:23<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.597       0.44      0.458      0.324      0.587      0.427      0.442      0.278\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      15/50      6.03G      1.025      1.427     0.6322     0.9517        222        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:23<00:00,  1.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.598      0.443      0.461      0.326      0.593       0.43      0.445      0.279\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      16/50      6.24G       1.02      1.413      0.626     0.9491        172        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:18<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.589      0.451      0.464      0.327      0.586      0.436      0.449      0.283\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      17/50      6.06G      1.015      1.408     0.6209     0.9462        122        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:24<00:00,  1.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.575      0.454      0.467      0.331      0.578      0.441      0.452      0.285\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      18/50      5.91G      1.013      1.401     0.6179     0.9454        135        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:18<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:42<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.584      0.448      0.469      0.333      0.597      0.429      0.454      0.286\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      19/50      5.88G      1.012      1.399     0.6152     0.9455        250        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:19<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:42<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.575      0.449       0.47      0.333      0.589      0.434      0.456      0.288\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      20/50      5.93G      1.008      1.388     0.6099     0.9425        200        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:15<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:42<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.573      0.447      0.471      0.334      0.572      0.437      0.458      0.289\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      21/50      5.93G      1.003      1.388     0.6085     0.9427        134        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:15<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:42<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.568       0.45      0.472      0.336      0.569      0.439       0.46       0.29\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      22/50      5.96G          1      1.375     0.6018     0.9406        151        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:28<00:00,  1.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:44<00:00,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.581      0.447      0.474      0.337      0.583      0.435       0.46      0.291\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      23/50      5.92G     0.9964      1.371     0.5996     0.9377        156        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:22<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.578       0.45      0.474      0.337      0.577      0.437      0.461       0.29\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      24/50      5.88G     0.9968      1.374     0.5978     0.9385        108        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:20<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.588      0.446      0.475      0.338      0.583      0.435      0.462      0.292\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      25/50         6G     0.9901      1.363     0.5939      0.937        183        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:21<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.589      0.446      0.477      0.339      0.588      0.432      0.462      0.292\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      26/50      6.22G     0.9886      1.358     0.5918     0.9367        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:17<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:42<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.587      0.448      0.476       0.34      0.582      0.438      0.463      0.293\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      27/50      5.97G     0.9842      1.349     0.5872     0.9334         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:19<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:42<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.592      0.445      0.477       0.34      0.588      0.433      0.463      0.293\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      28/50      6.01G     0.9858      1.355      0.586     0.9336        150        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:19<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:42<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.599       0.44      0.478      0.341      0.595      0.431      0.463      0.293\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      29/50      5.98G     0.9825      1.345     0.5817     0.9313        127        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4231/4231 [43:18<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     148031      0.595      0.445      0.479      0.341      0.592      0.434      0.465      0.295\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      30/50      5.92G     0.9773      1.343     0.5785     0.9297        166        640:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3836/4231 [39:21<04:02,  1.63it/s]"]}],"source":["# Train the model\n","model.train(data='/content/yolo_dataset/dataset.yaml', epochs=50, patience=10, imgsz=640, freeze=10, verbose=True, batch=-1, exist_ok=True,\n","      project='/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models', name='yolo_v9_video_coco/segment')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34416,"status":"ok","timestamp":1716772832006,"user":{"displayName":"XIAO YANG","userId":"10498861279155438245"},"user_tz":-120},"id":"InJQ75y4nShJ","outputId":"04807386-8e58-439e-d353-9e8838d5ec47"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING âš ï¸ /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/weights/last.pt appears to require 'dill', which is not in ultralytics requirements.\n","AutoInstall will run now for 'dill' but this feature will be removed in the future.\n","Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['dill'] not found, attempting AutoUpdate...\n","Collecting dill\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 116.3/116.3 kB 5.3 MB/s eta 0:00:00\n","Installing collected packages: dill\n","Successfully installed dill-0.3.8\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 5.9s, installed 1 package: ['dill']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n"]}],"source":["model = YOLO('/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/weights/last.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uxCeVbkTnpdK","outputId":"0cfea787-6900-4553-ca28-881aafa07c08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.22 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/weights/last.pt, data=/content/yolo_dataset/dataset.yaml, epochs=50, time=None, patience=10, batch=14, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models, name=segment, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/weights/last.pt, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 36.1MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment', view at http://localhost:6006/\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n","  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n","  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n","  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n","  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n","  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n","  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n"," 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n"," 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n"," 22        [15, 18, 21]  1   7951459  ultralytics.nn.modules.head.Segment          [81, 32, 256, [256, 512, 512]]\n","YOLOv9c-seg summary: 654 layers, 27897891 parameters, 27897875 gradients, 159.4 GFLOPs\n","\n","Transferred 999/999 items from pretrained weights\n","Freezing layer 'model.0.conv.weight'\n","Freezing layer 'model.0.bn.weight'\n","Freezing layer 'model.0.bn.bias'\n","Freezing layer 'model.1.conv.weight'\n","Freezing layer 'model.1.bn.weight'\n","Freezing layer 'model.1.bn.bias'\n","Freezing layer 'model.2.cv1.conv.weight'\n","Freezing layer 'model.2.cv1.bn.weight'\n","Freezing layer 'model.2.cv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.2.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.2.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv2.1.conv.weight'\n","Freezing layer 'model.2.cv2.1.bn.weight'\n","Freezing layer 'model.2.cv2.1.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.2.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.2.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.2.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.2.cv3.1.conv.weight'\n","Freezing layer 'model.2.cv3.1.bn.weight'\n","Freezing layer 'model.2.cv3.1.bn.bias'\n","Freezing layer 'model.2.cv4.conv.weight'\n","Freezing layer 'model.2.cv4.bn.weight'\n","Freezing layer 'model.2.cv4.bn.bias'\n","Freezing layer 'model.3.cv1.conv.weight'\n","Freezing layer 'model.3.cv1.bn.weight'\n","Freezing layer 'model.3.cv1.bn.bias'\n","Freezing layer 'model.3.cv2.conv.weight'\n","Freezing layer 'model.3.cv2.bn.weight'\n","Freezing layer 'model.3.cv2.bn.bias'\n","Freezing layer 'model.4.cv1.conv.weight'\n","Freezing layer 'model.4.cv1.bn.weight'\n","Freezing layer 'model.4.cv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.4.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.4.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv2.1.conv.weight'\n","Freezing layer 'model.4.cv2.1.bn.weight'\n","Freezing layer 'model.4.cv2.1.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.4.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.4.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.4.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.4.cv3.1.conv.weight'\n","Freezing layer 'model.4.cv3.1.bn.weight'\n","Freezing layer 'model.4.cv3.1.bn.bias'\n","Freezing layer 'model.4.cv4.conv.weight'\n","Freezing layer 'model.4.cv4.bn.weight'\n","Freezing layer 'model.4.cv4.bn.bias'\n","Freezing layer 'model.5.cv1.conv.weight'\n","Freezing layer 'model.5.cv1.bn.weight'\n","Freezing layer 'model.5.cv1.bn.bias'\n","Freezing layer 'model.5.cv2.conv.weight'\n","Freezing layer 'model.5.cv2.bn.weight'\n","Freezing layer 'model.5.cv2.bn.bias'\n","Freezing layer 'model.6.cv1.conv.weight'\n","Freezing layer 'model.6.cv1.bn.weight'\n","Freezing layer 'model.6.cv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.6.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.6.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv2.1.conv.weight'\n","Freezing layer 'model.6.cv2.1.bn.weight'\n","Freezing layer 'model.6.cv2.1.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.6.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.6.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.6.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.6.cv3.1.conv.weight'\n","Freezing layer 'model.6.cv3.1.bn.weight'\n","Freezing layer 'model.6.cv3.1.bn.bias'\n","Freezing layer 'model.6.cv4.conv.weight'\n","Freezing layer 'model.6.cv4.bn.weight'\n","Freezing layer 'model.6.cv4.bn.bias'\n","Freezing layer 'model.7.cv1.conv.weight'\n","Freezing layer 'model.7.cv1.bn.weight'\n","Freezing layer 'model.7.cv1.bn.bias'\n","Freezing layer 'model.7.cv2.conv.weight'\n","Freezing layer 'model.7.cv2.bn.weight'\n","Freezing layer 'model.7.cv2.bn.bias'\n","Freezing layer 'model.8.cv1.conv.weight'\n","Freezing layer 'model.8.cv1.bn.weight'\n","Freezing layer 'model.8.cv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv1.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv1.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv2.0.cv3.conv.weight'\n","Freezing layer 'model.8.cv2.0.cv3.bn.weight'\n","Freezing layer 'model.8.cv2.0.cv3.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv2.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv2.1.conv.weight'\n","Freezing layer 'model.8.cv2.1.bn.weight'\n","Freezing layer 'model.8.cv2.1.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv1.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv1.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv1.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv3.0.cv3.conv.weight'\n","Freezing layer 'model.8.cv3.0.cv3.bn.weight'\n","Freezing layer 'model.8.cv3.0.cv3.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.bn.bias'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.conv.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.bn.weight'\n","Freezing layer 'model.8.cv3.0.m.0.cv2.bn.bias'\n","Freezing layer 'model.8.cv3.1.conv.weight'\n","Freezing layer 'model.8.cv3.1.bn.weight'\n","Freezing layer 'model.8.cv3.1.bn.bias'\n","Freezing layer 'model.8.cv4.conv.weight'\n","Freezing layer 'model.8.cv4.bn.weight'\n","Freezing layer 'model.8.cv4.bn.bias'\n","Freezing layer 'model.9.cv1.conv.weight'\n","Freezing layer 'model.9.cv1.bn.weight'\n","Freezing layer 'model.9.cv1.bn.bias'\n","Freezing layer 'model.9.cv5.conv.weight'\n","Freezing layer 'model.9.cv5.bn.weight'\n","Freezing layer 'model.9.cv5.bn.bias'\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 195MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/labels/train... 59734 images, 41 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59734/59734 [01:24<00:00, 703.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_dataset/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels/val... 12473 images, 7 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12473/12473 [00:17<00:00, 698.27it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /content/yolo_dataset/images/val/Otras_2_001471.jpg: 1 duplicate labels removed\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset/labels/val.cache\n","Plotting labels to /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 163 weight(decay=0.0), 174 weight(decay=0.000546875), 173 bias(decay=0.0)\n","Resuming training /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/weights/last.pt from epoch 31 to 50 total epochs\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      31/50      6.21G     0.9813      1.371      0.594     0.9385         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [43:13<00:00,  1.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/446 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [04:24<00:00,  1.69it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.704       0.55      0.607      0.451      0.688      0.541      0.586      0.385\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      32/50      5.89G     0.9786      1.364     0.5898     0.9353         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [50:08<00:00,  1.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [04:46<00:00,  1.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.695       0.56      0.607      0.452      0.679      0.549      0.586      0.385\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      33/50      5.97G     0.9774      1.362     0.5912     0.9366         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [47:06<00:00,  1.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [05:04<00:00,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.693      0.558      0.607      0.451      0.674      0.548      0.586      0.385\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      34/50       6.3G     0.9755      1.351     0.5825     0.9331        131        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [45:04<00:00,  1.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:50<00:00,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.692      0.557      0.609      0.452      0.673      0.547      0.585      0.386\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      35/50      6.07G     0.9703      1.351     0.5817     0.9318         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [43:33<00:00,  1.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:55<00:00,  1.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.698      0.555      0.607      0.451      0.684      0.543      0.586      0.386\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      36/50      5.97G     0.9712      1.342     0.5778     0.9306        122        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [42:57<00:00,  1.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:49<00:00,  1.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.696      0.558       0.61      0.453      0.682      0.545      0.589      0.388\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      37/50      5.88G     0.9662      1.335     0.5727       0.93        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [44:22<00:00,  1.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:59<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.695      0.556      0.606      0.449       0.68      0.544      0.585      0.384\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      38/50      5.92G     0.9598      1.326     0.5684     0.9285         97        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [42:43<00:00,  1.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.687      0.557      0.609      0.452      0.678      0.544      0.587      0.386\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      39/50      5.88G     0.9602      1.327     0.5681     0.9272        111        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [42:36<00:00,  1.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:41<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.684      0.559      0.609      0.451       0.67      0.547      0.587      0.385\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      40/50      5.87G     0.9564      1.321     0.5653     0.9268        157        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [42:41<00:00,  1.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.684      0.558      0.604      0.447      0.671      0.543      0.583      0.382\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      41/50      5.87G     0.9605      1.289     0.5467     0.9268         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [40:38<00:00,  1.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:45<00:00,  1.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.678      0.558      0.604      0.447      0.679      0.538      0.583      0.381\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      42/50      5.88G     0.9547      1.277     0.5402     0.9245         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [41:10<00:00,  1.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:45<00:00,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.683      0.554      0.605      0.448      0.672       0.54      0.583      0.383\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      43/50         6G     0.9507      1.275     0.5354     0.9213         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [42:01<00:00,  1.69it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [04:02<00:00,  1.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.683      0.555      0.605      0.447       0.67      0.539      0.581      0.382\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      44/50      5.82G     0.9462      1.265     0.5285     0.9193         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [40:27<00:00,  1.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:46<00:00,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.685       0.55      0.604      0.447      0.682      0.531      0.581      0.382\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      45/50      5.87G     0.9419      1.258     0.5239     0.9183         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [40:24<00:00,  1.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:43<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.684      0.547      0.601      0.444      0.692      0.525      0.581      0.379\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      46/50      5.87G     0.9359      1.251     0.5164     0.9153         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4267/4267 [40:15<00:00,  1.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:40<00:00,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.678      0.546        0.6      0.442      0.691      0.525       0.58      0.377\n","\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 36, best model saved as best.pt.\n","To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","\n","16 epochs completed in 12.606 hours.\n","Optimizer stripped from /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/weights/last.pt, 56.3MB\n","Optimizer stripped from /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/weights/best.pt, 56.3MB\n","\n","Validating /content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment/weights/best.pt...\n","Ultralytics YOLOv8.2.22 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","YOLOv9c-seg summary (fused): 411 layers, 27686979 parameters, 0 gradients, 158.0 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv_transpose2d(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [03:34<00:00,  2.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all      12473     147680      0.695      0.558       0.61      0.453       0.68      0.545      0.588      0.387\n","                person      12473       6296      0.851      0.767      0.846      0.545      0.822      0.737      0.804      0.505\n","               bicycle      12473         56      0.652      0.468      0.514      0.325      0.598      0.429      0.434      0.228\n","                   car      12473        517      0.725      0.524       0.58       0.37      0.702      0.507      0.549      0.311\n","            motorcycle      12473         88      0.763      0.602      0.648      0.481      0.779      0.614      0.651      0.391\n","              airplane      12473         41      0.883      0.512       0.56      0.432      0.842      0.488      0.534      0.322\n","                   bus      12473         76      0.841      0.763      0.809      0.686      0.826      0.749      0.797      0.625\n","                 train      12473         40      0.864      0.791      0.887      0.731      0.863      0.789      0.881      0.698\n","                 truck      12473        109      0.745       0.44      0.571      0.426      0.716      0.422      0.528      0.366\n","                  boat      12473         85      0.567      0.447      0.482      0.328      0.572      0.435      0.487      0.292\n","         traffic light      12473        104      0.607      0.606      0.573      0.341      0.561      0.558      0.531      0.275\n","          fire hydrant      12473         21          1      0.644      0.765      0.649          1      0.644      0.765      0.592\n","             stop sign      12473         14      0.735      0.643      0.652       0.49      0.736      0.643      0.652      0.441\n","         parking meter      12473         15      0.733      0.533      0.613      0.446      0.642      0.467      0.525      0.387\n","                 bench      12473         90      0.547      0.188      0.238      0.167      0.542      0.184      0.227      0.127\n","                  bird      12473         93      0.386      0.538      0.476      0.333      0.382      0.527      0.465      0.292\n","                   cat      12473         35      0.869      0.971      0.965      0.857       0.87      0.971      0.965      0.785\n","                   dog      12473        644      0.404      0.283       0.23      0.183       0.41      0.286      0.233      0.184\n","                 horse      12473         46      0.548      0.609      0.616      0.492      0.557      0.602      0.614      0.425\n","                 sheep      12473     132303      0.821      0.695      0.816      0.548      0.816      0.687      0.808       0.51\n","                   cow      12473         87     0.0594      0.632      0.251      0.204     0.0567      0.598      0.228      0.174\n","              elephant      12473        109      0.669      0.835      0.779      0.624      0.677      0.835       0.79      0.515\n","                  bear      12473         13      0.663      0.769      0.804       0.71      0.733      0.846      0.873      0.652\n","                 zebra      12473         71      0.859      0.803      0.847      0.611      0.875      0.817      0.861      0.554\n","               giraffe      12473         41      0.639      0.927      0.915      0.712      0.609      0.878       0.86      0.564\n","              backpack      12473         81      0.629      0.259      0.334      0.206      0.631      0.259      0.307      0.196\n","              umbrella      12473        112      0.585       0.67      0.669        0.5      0.563      0.634      0.651      0.454\n","               handbag      12473        132       0.73      0.348      0.443      0.241      0.681      0.324      0.397      0.226\n","                   tie      12473         70      0.725      0.566      0.586      0.388      0.725      0.557      0.568      0.342\n","              suitcase      12473         65      0.644      0.723      0.781      0.589      0.665      0.738      0.769      0.532\n","               frisbee      12473         19      0.892      0.875      0.884      0.719      0.892      0.873      0.884      0.608\n","                  skis      12473         81      0.549      0.225      0.228     0.0925      0.487      0.199      0.208     0.0552\n","             snowboard      12473          5      0.209        0.2      0.258      0.217      0.212        0.2      0.322      0.209\n","           sports ball      12473         48      0.807      0.522      0.581      0.433      0.775        0.5      0.546      0.348\n","                  kite      12473         69      0.803      0.594      0.666      0.473      0.804      0.594      0.633      0.347\n","          baseball bat      12473         26      0.758      0.346      0.454      0.317      0.847      0.385       0.53      0.283\n","        baseball glove      12473         21      0.789      0.536      0.573        0.4      0.788      0.532      0.573      0.398\n","            skateboard      12473         33      0.679      0.788      0.772      0.595      0.682      0.788      0.769      0.412\n","             surfboard      12473         47      0.558      0.809      0.793      0.511      0.545      0.787      0.771      0.488\n","         tennis racket      12473         55      0.965      0.582      0.683      0.551      0.966      0.582      0.672       0.47\n","                bottle      12473        193      0.579      0.635      0.619      0.447      0.583      0.638       0.62      0.396\n","            wine glass      12473         79      0.893      0.582      0.701      0.453      0.876       0.57      0.684      0.353\n","                   cup      12473        167      0.751      0.551      0.618      0.449      0.736      0.539      0.587      0.396\n","                  fork      12473         38      0.693      0.416      0.447      0.329      0.559      0.334      0.337      0.195\n","                 knife      12473         44      0.528       0.25      0.295      0.195      0.439      0.205      0.243      0.121\n","                 spoon      12473         47      0.599      0.191      0.255      0.182      0.596      0.188      0.262      0.116\n","                  bowl      12473        136      0.684      0.566      0.597      0.461      0.623      0.515      0.511      0.332\n","                banana      12473         83      0.731      0.506      0.603      0.424      0.736      0.506       0.59      0.364\n","                 apple      12473         30      0.819        0.3      0.466      0.375       0.82        0.3      0.469       0.35\n","              sandwich      12473         40       0.65       0.45      0.508      0.361      0.583        0.4      0.412      0.314\n","                orange      12473         69      0.808      0.696      0.747      0.646      0.828       0.71      0.753      0.595\n","              broccoli      12473         70      0.767      0.429      0.595      0.383      0.767      0.424      0.573      0.329\n","                carrot      12473         87      0.727      0.368      0.495      0.323      0.731      0.368      0.477      0.282\n","               hot dog      12473         24      0.662      0.375      0.493      0.315      0.594      0.333      0.405      0.209\n","                 pizza      12473         52      0.787      0.788      0.883      0.728      0.807      0.808       0.87       0.67\n","                 donut      12473         87      0.591      0.697      0.674      0.518       0.58      0.681      0.663      0.462\n","                  cake      12473         41      0.777      0.732      0.805      0.569      0.784      0.707      0.777      0.524\n","                 chair      12473        461      0.676       0.43      0.537      0.366      0.661      0.415      0.507      0.262\n","                 couch      12473         62      0.643      0.629      0.682      0.527      0.594      0.565      0.575      0.435\n","          potted plant      12473         75      0.624      0.443      0.434      0.268      0.598      0.413      0.405      0.172\n","                   bed      12473         49      0.544      0.449      0.467      0.344      0.547      0.449      0.443      0.275\n","          dining table      12473        191      0.616      0.369      0.404      0.243      0.557      0.329      0.329      0.145\n","                toilet      12473         36      0.717      0.833      0.853      0.708      0.718      0.833      0.842      0.659\n","                    tv      12473         52      0.591      0.712      0.733      0.599      0.592      0.712       0.73      0.513\n","                laptop      12473         52       0.77      0.774      0.866      0.752      0.655      0.657       0.68      0.464\n","                 mouse      12473         18      0.776      0.889      0.925      0.743      0.779      0.889      0.925       0.71\n","                remote      12473         70      0.681      0.557       0.57      0.344      0.629      0.514      0.502      0.286\n","              keyboard      12473         29       0.55      0.655       0.58      0.412      0.551      0.655      0.579      0.412\n","            cell phone      12473         65      0.661      0.421      0.482      0.335      0.636      0.404      0.445      0.303\n","             microwave      12473         17      0.767      0.706      0.751      0.623      0.832      0.765      0.822      0.559\n","                  oven      12473         28      0.559      0.464      0.463      0.321      0.561      0.464      0.468      0.256\n","               toaster      12473          2          1          0      0.745      0.609          1          0      0.745      0.596\n","                  sink      12473         39      0.552      0.487      0.566      0.365      0.611      0.538      0.648      0.339\n","          refrigerator      12473         33      0.879      0.636      0.687       0.58       0.88      0.636      0.689      0.533\n","                  book      12473        198      0.629      0.232       0.36      0.212      0.526       0.19      0.226      0.118\n","                 clock      12473         59      0.764      0.881      0.909      0.688      0.765      0.881      0.897      0.621\n","                  vase      12473         41      0.727      0.634      0.702      0.491      0.769      0.659       0.73      0.439\n","              scissors      12473          5      0.612        0.2      0.197      0.197       0.62        0.2      0.197     0.0593\n","            teddy bear      12473         49      0.719      0.551       0.62      0.484      0.668       0.51       0.59       0.47\n","            toothbrush      12473         14      0.839      0.286      0.383      0.255      0.659      0.214       0.28      0.109\n","                  wolf      12473       2890      0.915      0.805      0.906       0.69      0.917      0.806      0.907      0.664\n","Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment\u001b[0m\n"]},{"data":{"text/plain":["ultralytics.utils.metrics.SegmentMetrics object with attributes:\n","\n","ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n","       79, 80])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7c6339596110>\n","curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)', 'Precision-Recall(M)', 'F1-Confidence(M)', 'Precision-Confidence(M)', 'Recall-Confidence(M)']\n","curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0024277,   0.0012138,           0],\n","       [          1,           1,           1, ...,  0.00021696,  0.00010848,           0],\n","       [          1,           1,           1, ...,  0.00031138,  0.00015569,           0],\n","       ...,\n","       [          1,           1,           1, ...,   0.0001755,  8.7748e-05,           0],\n","       [          1,           1,           1, ...,  9.6382e-05,  4.8191e-05,           0],\n","       [          1,           1,           1, ...,    0.017517,   0.0087587,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.16555,     0.16555,      0.2198, ...,           0,           0,           0],\n","       [   0.037813,    0.037813,     0.05562, ...,           0,           0,           0],\n","       [   0.064063,    0.064063,    0.091292, ...,           0,           0,           0],\n","       ...,\n","       [   0.038384,    0.038384,    0.070739, ...,           0,           0,           0],\n","       [   0.026991,    0.026991,    0.041144, ...,           0,           0,           0],\n","       [    0.48816,     0.48816,     0.58839, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.090909,    0.090909,     0.12478, ...,           1,           1,           1],\n","       [   0.019352,    0.019352,    0.028784, ...,           1,           1,           1],\n","       [   0.033394,    0.033394,    0.048508, ...,           1,           1,           1],\n","       ...,\n","       [   0.019679,    0.019679,    0.037108, ...,           1,           1,           1],\n","       [   0.013755,    0.013755,    0.021182, ...,           1,           1,           1],\n","       [    0.32699,     0.32699,     0.42524, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.92503,     0.92503,     0.92138, ...,           0,           0,           0],\n","       [    0.82143,     0.82143,     0.82143, ...,           0,           0,           0],\n","       [     0.7853,      0.7853,     0.77369, ...,           0,           0,           0],\n","       ...,\n","       [    0.77551,     0.77551,      0.7551, ...,           0,           0,           0],\n","       [    0.71429,     0.71429,     0.71429, ...,           0,           0,           0],\n","       [    0.96263,     0.96263,     0.95467, ...,           0,           0,           0]]), 'Confidence', 'Recall'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0018406,  0.00092032,           0],\n","       [          1,           1,           1, ...,   0.0001415,  7.0748e-05,           0],\n","       [          1,           1,           1, ...,  0.00029759,   0.0001488,           0],\n","       ...,\n","       [          1,           1,           1, ...,  0.00019813,  9.9063e-05,           0],\n","       [          1,           1,           1, ...,  6.9395e-05,  3.4698e-05,           0],\n","       [          1,           1,           1, ...,    0.018217,   0.0091086,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.16168,     0.16168,     0.21412, ...,           0,           0,           0],\n","       [   0.034525,    0.034525,    0.049574, ...,           0,           0,           0],\n","       [   0.063432,    0.063432,    0.089923, ...,           0,           0,           0],\n","       ...,\n","       [   0.039394,    0.039394,    0.070739, ...,           0,           0,           0],\n","       [   0.024291,    0.024291,     0.03703, ...,           0,           0,           0],\n","       [    0.48886,     0.48886,     0.58925, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.088786,    0.088786,     0.12156, ...,           1,           1,           1],\n","       [   0.017669,    0.017669,    0.025656, ...,           1,           1,           1],\n","       [   0.033065,    0.033065,     0.04778, ...,           1,           1,           1],\n","       ...,\n","       [   0.020197,    0.020197,    0.037108, ...,           1,           1,           1],\n","       [    0.01238,     0.01238,    0.019064, ...,           1,           1,           1],\n","       [    0.32746,     0.32746,     0.42586, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.90343,     0.90343,     0.89755, ...,           0,           0,           0],\n","       [       0.75,        0.75,     0.73214, ...,           0,           0,           0],\n","       [    0.77756,     0.77756,     0.76209, ...,           0,           0,           0],\n","       ...,\n","       [    0.79592,     0.79592,      0.7551, ...,           0,           0,           0],\n","       [    0.64286,     0.64286,     0.64286, ...,           0,           0,           0],\n","       [    0.96401,     0.96401,     0.95606, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n","fitness: 0.8760845581704041\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'metrics/precision(M)', 'metrics/recall(M)', 'metrics/mAP50(M)', 'metrics/mAP50-95(M)']\n","maps: array([     1.0494,      0.5529,     0.68084,     0.87162,      0.7544,      1.3112,      1.4291,     0.79212,     0.61959,     0.61642,      1.2408,     0.93105,     0.83342,     0.29425,     0.62538,      1.6411,     0.36684,     0.91742,      1.0582,     0.37807,      1.1395,      1.3619,      1.1646,      1.2761,\n","           0.40266,     0.95384,     0.46694,     0.72946,      1.1205,      1.3265,     0.14771,     0.42661,     0.78097,     0.82056,     0.59963,     0.79803,      1.0073,     0.99928,      1.0211,     0.84358,     0.80585,     0.84512,     0.52457,     0.31523,     0.29812,     0.79276,     0.78809,     0.72521,\n","            0.6757,      1.2416,     0.71162,      0.6043,     0.52337,      1.3977,     0.98018,      1.0929,     0.62761,     0.96125,     0.43948,     0.61906,     0.38799,      1.3673,       1.112,      1.2162,       1.453,     0.63021,     0.82346,     0.63794,      1.1823,     0.57793,      1.2047,     0.70336,\n","            1.1135,     0.33033,      1.3086,     0.93017,     0.25587,     0.95361,     0.84034,     0.36405,      1.3542])\n","names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush', 80: 'wolf'}\n","plot: True\n","results_dict: {'metrics/precision(B)': 0.6950950777636178, 'metrics/recall(B)': 0.5575842647652716, 'metrics/mAP50(B)': 0.6095534455364998, 'metrics/mAP50-95(B)': 0.4529994397118618, 'metrics/precision(M)': 0.6802062512941456, 'metrics/recall(M)': 0.5448438233945898, 'metrics/mAP50(M)': 0.5881989958159972, 'metrics/mAP50-95(M)': 0.38734424254942085, 'fitness': 0.8760845581704041}\n","save_dir: PosixPath('/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment')\n","seg: ultralytics.utils.metrics.Metric object\n","speed: {'preprocess': 0.12260720827886673, 'inference': 9.946844547779111, 'loss': 0.00048736939880963194, 'postprocess': 0.8265416088668517}\n","task: 'segment'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model.train(resume=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"X1fy6XcYWnYp","outputId":"2e64d0a8-eaa6-4256-f99a-d03d6954d447"},"outputs":[{"data":{"application/javascript":["\n","        (async () => {\n","            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["%reload_ext tensorboard\n","%tensorboard --logdir '/content/drive/MyDrive/TFM_Xiao/Code/YOLO/save_models/yolo_v9_video_coco/segment'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1mPKzlVQWnYq"},"outputs":[],"source":["drive.flush_and_unmount()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}